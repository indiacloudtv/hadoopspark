Ono of the Real-time Project Scenario is read HBase table from PySpark

===============================================================================================================================

Ono of the Real-time Project Scenario is read HBase from PySpark | Part 1 | Hands-On

Step 1: Create HBase table

create 'transaction_detail_hbase_tbl','transaction_data','customer_data'

(base) [hadoop@instance-1 ~]$ hbase shell
Java HotSpot(TM) 64-Bit Server VM warning: Using incremental CMS is deprecated and will likely be removed in a future release
HBase Shell
Use "help" to get list of supported commands.
Use "exit" to quit this interactive shell.
For Reference, please visit: http://hbase.apache.org/2.0/book.html#shell
Version 2.1.0-cdh6.2.0, rUnknown, Wed Mar 13 23:39:58 PDT 2019
Took 0.0041 seconds
hbase(main):001:0>
hbase(main):002:0> create 'transaction_detail_hbase_tbl','transaction_data','customer_data'
Created table transaction_detail_hbase_tbl
Took 5.7059 seconds
=> Hbase::Table - transaction_detail_hbase_tbl
hbase(main):003:0>


Step 2: Insert/Put few records to HBase table

put 'transaction_detail_hbase_tbl','1','transaction_data:transaction_amount','50.85'
put 'transaction_detail_hbase_tbl','1','transaction_data:transaction_card_type','MasterCard'
put 'transaction_detail_hbase_tbl','1','transaction_data:transaction_ecommerce_website_name','www.ebay.com'
put 'transaction_detail_hbase_tbl','1','transaction_data:transaction_datetime','2019-05-14 15:24:12'
put 'transaction_detail_hbase_tbl','1','transaction_data:transaction_product_name','Laptop'
put 'transaction_detail_hbase_tbl','1','customer_data:transaction_city_name','Mumbai'
put 'transaction_detail_hbase_tbl','1','customer_data:transaction_country_name','India'

put 'transaction_detail_hbase_tbl','2','transaction_data:transaction_amount','259.12'
put 'transaction_detail_hbase_tbl','2','transaction_data:transaction_card_type','MasterCard'
put 'transaction_detail_hbase_tbl','2','transaction_data:transaction_ecommerce_website_name','www.amazon.com'
put 'transaction_detail_hbase_tbl','2','transaction_data:transaction_datetime','2019-05-14 15:24:13'
put 'transaction_detail_hbase_tbl','2','transaction_data:transaction_product_name','Wrist Band'
put 'transaction_detail_hbase_tbl','2','customer_data:transaction_city_name','Pune'
put 'transaction_detail_hbase_tbl','2','customer_data:transaction_country_name','India'

put 'transaction_detail_hbase_tbl','3','transaction_data:transaction_amount','328.16'
put 'transaction_detail_hbase_tbl','3','transaction_data:transaction_card_type','MasterCard'
put 'transaction_detail_hbase_tbl','3','transaction_data:transaction_ecommerce_website_name','www.flipkart.com'
put 'transaction_detail_hbase_tbl','3','transaction_data:transaction_datetime','2019-05-14 15:24:14'
put 'transaction_detail_hbase_tbl','3','transaction_data:transaction_product_name','TV Stand'
put 'transaction_detail_hbase_tbl','3','customer_data:transaction_city_name','New York City'
put 'transaction_detail_hbase_tbl','3','customer_data:transaction_country_name','United States'

put 'transaction_detail_hbase_tbl','4','transaction_data:transaction_amount','399.06'
put 'transaction_detail_hbase_tbl','4','transaction_data:transaction_card_type','Visa'
put 'transaction_detail_hbase_tbl','4','transaction_data:transaction_ecommerce_website_name','www.snapdeal.com'
put 'transaction_detail_hbase_tbl','4','transaction_data:transaction_datetime','2019-05-14 15:24:15'
put 'transaction_detail_hbase_tbl','4','transaction_data:transaction_product_name','TV Stand'
put 'transaction_detail_hbase_tbl','4','customer_data:transaction_city_name','New Delhi'
put 'transaction_detail_hbase_tbl','4','customer_data:transaction_country_name','India'

put 'transaction_detail_hbase_tbl','5','transaction_data:transaction_amount','194.52'
put 'transaction_detail_hbase_tbl','5','transaction_data:transaction_card_type','Visa'
put 'transaction_detail_hbase_tbl','5','transaction_data:transaction_ecommerce_website_name','www.ebay.com'
put 'transaction_detail_hbase_tbl','5','transaction_data:transaction_datetime','2019-05-14 15:24:16'
put 'transaction_detail_hbase_tbl','5','transaction_data:transaction_product_name','External Hard Drive'
put 'transaction_detail_hbase_tbl','5','customer_data:transaction_city_name','Rome'
put 'transaction_detail_hbase_tbl','5','customer_data:transaction_country_name','Italy'

Step 3: Create Hive table pointing to HBase table using HBaseStorageHandler

CREATE EXTERNAL TABLE transaction_detail_hive_tbl(transaction_id int, transaction_card_type string, transaction_ecommerce_website_name string, transaction_product_name string, transaction_datetime string, transaction_amount double, transaction_city_name string, transaction_country_name string) STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES ("hbase.columns.mapping"=":key,transaction_data:transaction_card_type,transaction_data:transaction_ecommerce_website_name,transaction_data:transaction_product_name,transaction_data:transaction_datetime,transaction_data:transaction_amount,customer_data:transaction_city_name,customer_data:transaction_country_name") TBLPROPERTIES ("hbase.table.name"="transaction_detail_hbase_tbl");

Step 4: Query Hive table from Hive CLI or Hue browser to verify Hive table and HBase table integration is working

select * from transaction_detail_hive_tbl;

===============================================================================================================================

Ono of the Real-time Project Scenario is read HBase from PySpark | Part 2 | Hands-On

Step 1: Create SparkSession object with Hive enable option in PySpark program

from pyspark.sql import SparkSession
spark = SparkSession \
    .builder \
    .appName("Read HBase Table using PySpark Demo") \
    .config("spark.jars", "/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/lib/hive/lib/hive-hbase-handler-2.1.1-cdh6.2.0.jar") \
    .config("spark.executor.extraClassPath", "/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/lib/hive/lib/hive-hbase-handler-2.1.1-cdh6.2.0.jar") \
    .config("spark.executor.extraLibrary", "/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/lib/hive/lib/hive-hbase-handler-2.1.1-cdh6.2.0.jar") \
    .config("spark.driver.extraClassPath", "/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/lib/hive/lib/hive-hbase-handler-2.1.1-cdh6.2.0.jar") \
    .enableHiveSupport()\
    .getOrCreate()

Step 2: Read/query Hive table using SparkSession object which internally uses HiveContext to make Hive connection(Metastore) and get the records

transaction_detail_df = spark.sql("use default")
transaction_detail_df = spark.sql("select * from transaction_detail_hive_tbl")

Step 3: As usual do some analysis on the data in the DataFrame from Hive table


DataSet used:
-------------

transaction_amount,transaction_card_type,transaction_ecommerce_website_name,transaction_country_name,transaction_datetime,transaction_id,transaction_city_name,transaction_product_name
50.85,MasterCard,www.ebay.com,India,2019-05-14 15:24:12,1,Mumbai,Laptop
259.12,MasterCard,www.amazon.com,India,2019-05-14 15:24:13,2,Pune,Wrist Band
328.16,MasterCard,www.flipkart.com,United States,2019-05-14 15:24:14,3,New York City,TV Stand
399.06,Visa,www.snapdeal.com,Inida,2019-05-14 15:24:15,4,New Delhi,TV Stand
194.52,Visa,www.ebay.com,Italy,2019-05-14 15:24:16,5,Rome,External Hard Drive


Reference link for other option for reading HBase table using Spark/PySpark:

https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-using-spark-query-hbase
https://mapr.com/developer-portal/mapr-tutorials/loading-hbase-tables-spark